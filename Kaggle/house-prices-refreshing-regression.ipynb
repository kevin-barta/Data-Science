{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\npd.set_option('display.max_columns', None)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-20T21:11:20.096014Z","iopub.execute_input":"2023-08-20T21:11:20.096437Z","iopub.status.idle":"2023-08-20T21:11:20.112742Z","shell.execute_reply.started":"2023-08-20T21:11:20.096402Z","shell.execute_reply":"2023-08-20T21:11:20.111486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    train = pd.read_csv('/kaggle/input/housingpricesadvancedregressiontechniques/train.csv')\n    test = pd.read_csv('/kaggle/input/housingpricesadvancedregressiontechniques/test.csv')\nexcept:\n    train = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n    test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n\ntarget = 'SalePrice'\n\ntrain","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:37.289218Z","iopub.execute_input":"2023-08-20T20:17:37.289602Z","iopub.status.idle":"2023-08-20T20:17:37.397313Z","shell.execute_reply.started":"2023-08-20T20:17:37.289570Z","shell.execute_reply":"2023-08-20T20:17:37.396318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_one_hots(df, cat_cols):\n    one_hots = pd.get_dummies(df[cat_cols])\n    df = pd.concat([df, one_hots], axis=1)\n    return df.loc[:,~df.T.duplicated(keep='first')]\n\ndef prep_one_hots(train, test, cat_cols):\n    split_idx = len(train)\n    df = pd.concat([train, test]).reset_index(drop=True)\n    df = get_one_hots(df, cat_cols)\n    return df[:split_idx], df[split_idx:].reset_index(drop=True)\n\npercent_missing = train.isnull().sum() / len(train)\ndrop_cols = percent_missing[percent_missing > 0.5].index.to_list()\n\nprint(f'\\nColumns with > 0.5 values missing: {drop_cols}\\n')\n\nnum_cols = list(train.select_dtypes(np.number).columns)\n\ncat_feats = list(train.select_dtypes(exclude=np.number).columns)\n\ntrain,test = prep_one_hots(train, test, cat_feats)\n\ntrain = train.select_dtypes(np.number)\ntest = test.select_dtypes(np.number)\n\n# Save the column names for the one hot cols for later\none_hot_cols = train.columns[~train.columns.isin(num_cols)]\n\ntrain.info()\ntest.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:39.097119Z","iopub.execute_input":"2023-08-20T20:17:39.097486Z","iopub.status.idle":"2023-08-20T20:17:39.676371Z","shell.execute_reply.started":"2023-08-20T20:17:39.097456Z","shell.execute_reply":"2023-08-20T20:17:39.675231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:41.136997Z","iopub.execute_input":"2023-08-20T20:17:41.137373Z","iopub.status.idle":"2023-08-20T20:17:41.280254Z","shell.execute_reply.started":"2023-08-20T20:17:41.137344Z","shell.execute_reply":"2023-08-20T20:17:41.279490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler, StandardScaler\n\nclass CustomScaler:\n    def __init__(self, inp_df, predictors, target):\n        self._inp_df = inp_df\n        self._predictors = predictors\n        self._target = target\n        \n    def set_scaled_df(self, scaler):\n        self.scaler_obj = scaler()\n        scaled_df = self.scaler_obj.fit_transform(self._inp_df[self._predictors])\n        scaled_df = pd.DataFrame(scaled_df, columns=self.scaler_obj.get_feature_names_out())\n        scaled_df[self._target] = self._inp_df[self._target]\n        self._scaled_df = scaled_df\n    \n    def get_scaled_df(self):\n        return self._scaled_df\n    \n    def scaled_test_df(self, test_df):\n        scaled_test_df = self.scaler_obj.transform(test_df[self._predictors])\n        self._scaled_test_df = pd.DataFrame(scaled_test_df, columns=self.scaler_obj.get_feature_names_out())\n        \n    def get_scaled_test_df(self):\n        return self._scaled_test_df\n    \n\ncs = CustomScaler(train, num_cols, target)\ncs.set_scaled_df(StandardScaler)\n\nscaled_train = cs.get_scaled_df()\nscaled_train = pd.concat([scaled_train,train[one_hot_cols]], axis=1)\n\n# Test Set scaling\n# set a dummy Target for input into the Scaler\ntest[target] = 0\n\n# scale the test set\ncs.scaled_test_df(test)\nscaled_test = cs.get_scaled_test_df()\n\n# drop the dummy Target\nscaled_test = scaled_test.drop(target, axis=1)\n\n# combine the hot columns to the scaled test\nscaled_test = pd.concat([scaled_test,test[one_hot_cols]], axis=1)\nscaled_test","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:42.947340Z","iopub.execute_input":"2023-08-20T20:17:42.948717Z","iopub.status.idle":"2023-08-20T20:17:43.113212Z","shell.execute_reply.started":"2023-08-20T20:17:42.948666Z","shell.execute_reply":"2023-08-20T20:17:43.112110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge, Lasso\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor as VIF \n\n\ndef nan_regression(df: pd.DataFrame, predictors: list, mvc: str, thresh: float) -> pd.Series:\n    \"\"\"\n    Perform regression to fill missing values in a column using predictors.\n\n    Args:\n        df (pd.DataFrame): Input dataframe.\n        predictors (list): List of predictor variable column names.\n        mvc (str): Column name with missing values to be filled.\n\n    Returns:\n        pd.Series: Series with missing values filled using regression.\n    \"\"\"\n    lr = Ridge()\n    has_nans = df[df[mvc].isnull() == True][predictors + [mvc]]\n    no_nans = df[df[mvc].isnull() == False][predictors + [mvc]]\n    X = no_nans[predictors]\n    y = no_nans[mvc]\n    lr.fit(X, y)\n    train_pred = lr.score(X, y)\n    print(f'{mvc} training score: {train_pred :.3f}\\n')\n    if train_pred > thresh:\n        pred = lr.predict(has_nans[predictors])\n        has_nans[mvc] = np.round(np.where(pred < 0, np.mean(y), pred))\n        return pd.concat([no_nans[mvc], has_nans[mvc]], axis=0).sort_index()\n    else:\n        print(f'Score for {mvc} too low for filling missing data')\n        return df[mvc]\n    \n    \ndef clean_data(train, test, target):\n    split_idx = len(train)\n    df = pd.concat([train, test]).reset_index(drop=True)\n    missing_val_cols = list(df.columns[df.isnull().any()])\n    missing_val_cols = [col for col in missing_val_cols if target not in col]\n    num_cols = df._get_numeric_data().columns\n    no_missing_val_cols = list(num_cols[(~df[num_cols].isnull().any())])\n    \n    for mvc in missing_val_cols:\n        predictors = no_missing_val_cols\n        predictors = [col for col in predictors if mvc not in col]\n\n        if np.issubdtype(df[mvc].dtype, np.number):\n            replacement = nan_regression(df, predictors, mvc, 0.5)\n            if replacement is not None:\n                df[mvc] = replacement\n            else:\n                df[mvc] = np.nan\n                \n    df = df.dropna(axis=1)\n    #df.info()\n\n    if df[[col for col in df.columns if target not in col]].isna().sum().sum() > 0:\n        print('\\nMore cleaning to do')\n        print(df.isna().sum())\n    else: \n        print('\\nCleaning complete')\n        \n    return df[:split_idx], df[split_idx:].reset_index(drop=True)\n\n\nscaled_clean_train, scaled_clean_test = clean_data(scaled_train, scaled_test, target)\n## scaled_clean_train = scaled_clean_train[(scaled_clean_train.abs() < 3) | (scaled_clean_train.columns == target)].dropna()\n\nscaled_clean_train[target] = train[target]\n\npreds = list(scaled_clean_train.select_dtypes(np.number).columns) \npreds = [col for col in preds if target not in col]\n\n# drop Id column\nif 'Id' in scaled_clean_train.columns:\n    scaled_clean_train = scaled_clean_train.drop('Id', axis=1)\nif 'Id' in scaled_clean_test.columns:\n    scaled_clean_test = scaled_clean_test.drop('Id', axis=1)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:43.885403Z","iopub.execute_input":"2023-08-20T20:17:43.885779Z","iopub.status.idle":"2023-08-20T20:17:44.938950Z","shell.execute_reply.started":"2023-08-20T20:17:43.885749Z","shell.execute_reply":"2023-08-20T20:17:44.937936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaled_clean_test.isna().sum().sort_values(ascending=0)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:46.881164Z","iopub.execute_input":"2023-08-20T20:17:46.882259Z","iopub.status.idle":"2023-08-20T20:17:46.892093Z","shell.execute_reply.started":"2023-08-20T20:17:46.882223Z","shell.execute_reply":"2023-08-20T20:17:46.891152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_feats = [col for col in scaled_clean_train.columns if target not in col]\n\ncorr_df = scaled_clean_train[all_feats].corr()\n\ncorr_threshold = 0.6\nsize = 50\nplt.figure(figsize=(size, size))\nsns.heatmap(corr_df[(corr_df.abs() > corr_threshold) & (corr_df.abs() < 1)].dropna(how='all',axis=1).dropna(how='all',axis=0), annot=True);","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:48.877079Z","iopub.execute_input":"2023-08-20T20:17:48.878192Z","iopub.status.idle":"2023-08-20T20:17:53.399171Z","shell.execute_reply.started":"2023-08-20T20:17:48.878140Z","shell.execute_reply":"2023-08-20T20:17:53.398080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_collinear_features(df_model, target_var, threshold=0.2, verbose=0):\n    '''\n    Objective:\n        Remove collinear features in a dataframe with a correlation coefficient\n        greater than the threshold and which have the least correlation with the target (dependent) variable. Removing collinear features can help a model \n        to generalize and improves the interpretability of the model.\n\n    Inputs: \n        df_model: features dataframe\n        target_var: target (dependent) variable\n        threshold: features with correlations greater than this value are removed\n        verbose: set to \"True\" for the log printing\n\n    Output: \n        dataframe that contains only the non-highly-collinear features\n    '''\n\n    # Calculate the correlation matrix\n    corr_matrix = df_model.drop(target_var, 1).corr()\n    iters = range(len(corr_matrix.columns) - 1)\n    drop_cols = []\n    dropped_feature = \"\"\n\n    # Iterate through the correlation matrix and compare correlations\n    for i in iters:\n        for j in range(i+1): \n            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n            col = item.columns\n            row = item.index\n            val = abs(item.values)\n\n            # If correlation exceeds the threshold\n            if val >= threshold:\n                # Print the correlated features and the correlation value\n                if verbose:\n                    print(f\"{col.values[0]} | {row.values[0]} | {round(val[0][0], 2)}\")\n                col_value_corr = df_model[col.values[0]].corr(df_model[target_var])\n                row_value_corr = df_model[row.values[0]].corr(df_model[target_var])\n                if verbose:\n                    print(f\"{col.values[0]}: {np.round(col_value_corr, 3)}\")\n                    print(f\"{row.values[0]}: {np.round(row_value_corr, 3)}\")\n                if col_value_corr < row_value_corr:\n                    drop_cols.append(col.values[0])\n                    dropped_feature = f\"dropped: {col.values[0]}\"\n                else:\n                    drop_cols.append(row.values[0])\n                    dropped_feature = f\"dropped: {row.values[0]}\"\n                if verbose:\n                    print(dropped_feature)\n                    print(\"-----------------------------------------------------------------------------\")\n\n    # Drop one of each pair of correlated columns\n    drops = set(drop_cols)\n    df_model = df_model.drop(columns=drops)\n    if verbose:\n        print(\"dropped columns: \")\n        print(list(drops))\n        print(\"-----------------------------------------------------------------------------\")\n        print(\"used columns: \")\n        print(df_model.columns.tolist())\n\n    return df_model\n\n### Remove correlated features removing features corr.abs > 0.7\n# Dormann, C. F., J. Elith, S. Bacher, et al. 2013. Collinearity\nscaled_clean_train = remove_collinear_features(scaled_clean_train, target, 0.6)\nscaled_clean_train","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:17:57.463161Z","iopub.execute_input":"2023-08-20T20:17:57.463996Z","iopub.status.idle":"2023-08-20T20:18:01.554733Z","shell.execute_reply.started":"2023-08-20T20:17:57.463948Z","shell.execute_reply":"2023-08-20T20:18:01.553673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# training data split percentage OOS to IS\ntrain_split_pct_OOS = 0.3\n\n# split the training data into IS and OOS\ntrain_IS, train_OOS = train_test_split(scaled_clean_train, test_size=train_split_pct_OOS, shuffle=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:08.721597Z","iopub.execute_input":"2023-08-20T20:11:08.722293Z","iopub.status.idle":"2023-08-20T20:11:08.733128Z","shell.execute_reply.started":"2023-08-20T20:11:08.722254Z","shell.execute_reply":"2023-08-20T20:11:08.731748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# fit training IS data to Linear Regression Model\nmodel = LinearRegression()\nmodel.fit(train_IS.drop(target, axis=1), train_IS[target])\n\n#print(model.coef_)\n#pd.DataFrame(model.coef_, train_IS.drop(target, axis=1).columns, columns = ['Coeff'])\n\n# predict the target of the training OOS data\npredictions = model.predict(train_OOS.drop(target, axis=1))\n\n#predictions = (np.rint(predictions)).astype(int)\n#print(predictions)\n\n# fix for predictions that are way off\npredictions[predictions > 1000000] = 0\npredictions[predictions < -1000000] = 0\n\nplt.scatter(train_OOS[target], predictions)\nplt.show()\nplt.hist(train_OOS[target] - predictions)\nplt.show()\n\nfrom sklearn import metrics\n\nprint('Mean Absolute Error: ' + str(metrics.mean_absolute_error(train_OOS[target], predictions)))\n\nprint('Mean Squared Error: ' + str(metrics.mean_squared_error(train_OOS[target], predictions)))\n\nprint('Root Mean Squared Error: ' + str(np.sqrt(metrics.mean_squared_error(train_OOS[target], predictions))))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:08.734297Z","iopub.execute_input":"2023-08-20T20:11:08.735092Z","iopub.status.idle":"2023-08-20T20:11:09.275408Z","shell.execute_reply.started":"2023-08-20T20:11:08.735055Z","shell.execute_reply":"2023-08-20T20:11:09.274365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\n\ndef get_lin_reg(X, y):\n    \"\"\"\n    Perform linear regression using ordinary least squares (OLS) method.\n\n    Parameters:\n        X (array-like): Input feature matrix.\n        y (array-like): Target variable.\n\n    Returns:\n        statsmodels.regression.linear_model.RegressionResultsWrapper: Results of the linear regression.\n    \"\"\"\n    X2 = sm.add_constant(X)  # Add a constant column to the feature matrix\n    est = sm.OLS(y, X2, missing='drop')  # Fit the linear regression model\n    est2 = est.fit()  # Get the results of the linear regression\n    return est2\n\n\n#X = train_IS.drop(target, axis=1)\n#y = train_IS[target]\nX = scaled_clean_train.drop(target, axis=1)\ny = scaled_clean_train[target]\n\np_thresh = 0.01\nverbose = 1\n\nstart_r2 = get_lin_reg(X, y).rsquared_adj\n\nrunning = True\ndrop = ''\n\nconst_count = 0\n\nprint(f'Starting | n_features: {len(X.columns)} | adj_r2: {start_r2 : .4f}')\nwhile running: \n    results = get_lin_reg(X, y)\n    features = list(X.columns)\n    max_p = results.pvalues.max()\n    if max_p > p_thresh:     \n        if drop != 'const':\n            drop = results.pvalues.idxmax()\n            \n        if drop == 'const':\n            drop = results.pvalues.nlargest(2).index[1]\n            print(f'WARNING: const max taking second: {drop}')\n        \n        if drop != 'const':\n            X = X.drop(drop, axis=1)\n        else:\n            continue \n            \n        if verbose:\n            print(f'Dropping: {drop} {max_p : .3f}')\n        \n    else:\n        running = False\n        print(f'Finished | n_features: {len(features)} | adj_r2: {results.rsquared_adj : .4f}\\n')\n        print(results.summary())\n        final_features = X.columns","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:18:50.795483Z","iopub.execute_input":"2023-08-20T20:18:50.795881Z","iopub.status.idle":"2023-08-20T20:19:06.684055Z","shell.execute_reply.started":"2023-08-20T20:18:50.795847Z","shell.execute_reply":"2023-08-20T20:19:06.683157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport seaborn as sns\n\n\nclass CustomRegression:\n    def __init__(self, data, predictors, target):\n        self._data = data\n        self._X = data[predictors]\n        self._y = data[target]\n        self._predictors = list(predictors)\n        self._target = target\n        self._n = len(self._data)\n        self._p = len(self._predictors)\n        \n    def set_data(self, data, predictors, target):\n        self._data = data\n        self._X = data[predictors]\n        self._y = data[target]\n        self._predictors = list(predictors)\n        self._target = target\n        self._n = len(self._data)\n        self._p = len(self._predictors)\n   \n    def fit_reg(self, reg):\n        self._model = reg\n        self._model.fit(self._X, self._y)\n        self.results(self._X, self._y)\n\n    def predict(self, data, predictors, target):\n        self.set_data(data, predictors, target)\n        self._data['y_pred'] = self._model.predict(self._X)\n        self._data['resids'] = abs(self._y) - abs(self._data['y_pred'])\n        self.results(self._X, self._y)\n\n    def results(self, X, y):\n        self._r2 = self._model.score(X, y)\n        self.set_adj_r2()\n        self.set_resids()\n        self.set_results_df(X, y)  \n        #if self._p > 1:\n        #    self.set_fstat()       \n        self._ssr = np.sum(self.get_resids()**2)\n        self.set_log_likelihood()\n        self.resids_assumptions()\n\n    def get_data(self):\n        return self._data\n    \n    def get_r2(self):\n        return self._r2\n\n    def set_adj_r2(self):\n        self._adj_r2 = 1 - (1 - self._r2)*(self._n - 1) / (self._n - self._p - 1)\n    \n    def set_resids(self):\n        self._data['y_pred'] = self._model.predict(self._X)\n        self._data['resids'] = abs(self._data[self._target]) - abs(self._data['y_pred'])\n\n    def get_resids(self):\n        return self._data['resids'].values\n \n    def set_results_df(self, X, y):\n        from scipy.stats import t\n\n        feature_names = ['intercept'] + self._predictors\n        \n        params = np.append(self._model.intercept_, self._model.coef_)\n        predictions = self._model.predict(X)\n               \n        X2 = np.append(np.ones((len(X),1)), X, axis=1)\n        MSE = (np.sum((y-predictions)**2)) / (len(X2) - len(X2[0]))\n\n        var_b = MSE*(np.linalg.pinv(np.dot(X2.T, X2)).diagonal())\n        sd_b = np.sqrt(var_b)\n        ts_b = params / sd_b\n\n        p_values = [ 2*(1 - t.cdf(np.abs(i), (len(X2) - len(X2[0])))) for i in ts_b]\n\n        sd_b = np.round(sd_b,3)\n        ts_b = np.round(ts_b,3)\n        p_values = np.round(p_values,3)\n        params = np.round(params,4)\n        \n        results_df = pd.DataFrame()\n        results_df.index, results_df[\"coef\"], results_df[\"std_err\"], results_df[\"t_value\"], results_df[\"p_value\"] = [feature_names, params, sd_b, ts_b, p_values]\n        results_df['0.025'] = results_df[\"coef\"] - (2* results_df[\"std_err\"])\n        results_df['0.975'] = results_df[\"coef\"] + (2* results_df[\"std_err\"])\n        self._results_df = results_df\n        \n    def get_results_df(self, digits=4):\n        return self._results_df.round(digits)\n\n    def set_fstat(self):\n        from symbulate import F\n        self._fstat = (self._r2 / (1 - self._r2)) * ((self._n - self._p - 1) / self._p)\n        self._fstat_pval = 1 - F( (self._n-1), (self._p-1)).cdf(self._fstat)\n\n    def get_fstat(self):\n        return self._fstat\n\n    def summary(self, digits=4):\n        display(pd.DataFrame([self.reg_metrics(digits)], index=['metrics']))\n        display(self.get_results_df(digits))\n        display(pd.DataFrame([self.error_metrics(digits)], index=['errors']))\n    \n    ### Assumptions\n    def resids_normal(self, alpha=0.05):\n        ### Normally distributed residuals\n        # Above 0.05 == normal\n        from statsmodels.stats.diagnostic import normal_ad\n\n        self._ad_crit_val, self._ad_p_value = normal_ad(self._data['resids'])\n        if self._ad_p_value > alpha:\n            return True\n        return False\n    \n    def resids_autocorr(self):\n        ### Autocorrelation in the residuals\n        ##  looking for between 1.5 - 2.5\n        from statsmodels.stats.stattools import durbin_watson\n        self._durbinWatson = durbin_watson(self._data['resids'])\n        if (self._durbinWatson > 1.5) and (self._durbinWatson < 2.5):\n            return False\n        return True\n \n    def resids_assumptions(self):\n        normal_assumption = self.resids_normal()\n        autocorr_assumption = self.resids_autocorr()\n        print(f'residuals normally distributed: {normal_assumption}')\n        print(f'residuals autocorrelated:       {autocorr_assumption}')\n        if normal_assumption and not autocorr_assumption:\n            return True\n        return False\n\n    def reg_metrics(self, digits=4):\n        statistics = {\n            'n_obs' : self._n,\n            'n_pred' : self._p,\n            'ssr' : round(self._ssr, digits),\n            'log_likelihood' : round(self._ll, digits),\n            \n            'r2' : round(self._r2, digits),\n            'adj_r2' : round(self._adj_r2, digits),\n            #'f_stat' : round(self._fstat, digits),\n            #'P(f_stat)' : round(self._fstat_pval, digits),\n            \n            'ad' : round(self._ad_crit_val, digits),\n            'P(ad)' : round(self._ad_p_value, digits),\n            'durbin_watson' : round(self._durbinWatson, digits),\n        }\n        return statistics\n    \n    def error_metrics(self, digits=4):\n        from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, median_absolute_error\n        \n        self.set_AIC_BIC()\n        \n        y_true = self._y\n        y_pred = self._data['y_pred']\n\n        mse = mean_squared_error(y_true, y_pred)\n        rmse = np.sqrt(mse)\n        mae = mean_absolute_error(y_true, y_pred)\n        mape = mean_absolute_percentage_error(y_true, y_pred)\n        medae = median_absolute_error(y_true, y_pred)\n        log_rmse = np.sqrt(mean_squared_error(np.log(y_true), np.log(y_pred)))\n        \n        self._error_metrics = {\n            'MSE': round(mse, digits),\n            'RMSE': round(rmse, digits),\n            'Log_RMSE' : round(log_rmse, digits),\n            'MAE': round(mae, digits),\n            'MedAE' : round(medae, digits),\n            'MAPE': round(mape, digits), \n            'AIC' : round(self._AIC, digits),\n            'BIC' : round(self._BIC, digits),\n        }\n        return self._error_metrics\n\n    def set_log_likelihood(self):\n        n = self._n\n        k = self._p\n        residuals = self._data['resids']\n        self._ll = -(n * 1/2) * (1 + np.log(2 * np.pi)) - (n / 2) * np.log(residuals.dot(residuals) / n)\n    \n    def get_log_likelihood(self):\n        return self._ll \n\n    def set_AIC_BIC(self):\n        ll = self.get_log_likelihood()\n        n = self._n\n        k = self._p + 1\n\n        self._AIC = (-2 * ll) + (2 * k)\n        self._BIC = (-2 * ll) + (k * np.log(n))\n                        \n    ### Plotting\n    def plot_resid_hist(self):\n        sns.displot(self._data['resids'], kde=1).set(title='Residuals')\n        plt.show()\n\n    def plot_residuals(self, std=True):\n        fig, ax = plt.subplots(2, 1, figsize=(14, 7))\n        if std:\n            resids = (self._data['resids'] - np.mean(self._data['resids'])) / np.std(self._data['resids'], ddof=1)\n        else:\n            resids = self._data['resids']\n        ax[0].scatter(self._data['y_pred'], resids, alpha=0.75)     \n        ax[0].set_xlabel('Fitted value') \n        ax[0].set_ylabel('Residual')\n        ax[0].set_title('Residuals plot')\n\n        ax[1].scatter(self._data.index, resids, alpha=0.75) \n        ax[1].set_xlabel('Index') \n        ax[1].set_ylabel('Residual')    \n\n        if std:\n            for i in range(2):\n                ax[i].axhline(0, c='k', ls='--')\n                ax[i].axhline(3, c='r', ls='--')\n                ax[i].axhline(-3, c='r', ls='--')\n        plt.show()\n        return resids[np.abs(resids) > 3]\n    \n    def plot_scatter(self):\n        sns.jointplot(self._data, x='y_pred', y=self._target)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:38.236867Z","iopub.execute_input":"2023-08-20T20:11:38.237802Z","iopub.status.idle":"2023-08-20T20:11:38.297915Z","shell.execute_reply.started":"2023-08-20T20:11:38.237757Z","shell.execute_reply":"2023-08-20T20:11:38.296785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''scaled_clean_train[target] = train[target]#np.log(scaled_clean_train[target])\n\ncr = CustomRegression(train_IS, X.columns, y.name)\ncr.fit_reg(Lasso())\ncr.summary()\ncr.plot_residuals()\ncr.plot_scatter()'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:38.299770Z","iopub.execute_input":"2023-08-20T20:11:38.300536Z","iopub.status.idle":"2023-08-20T20:11:39.670325Z","shell.execute_reply.started":"2023-08-20T20:11:38.300497Z","shell.execute_reply":"2023-08-20T20:11:39.669065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''cr.predict(train_OOS,X.columns, y.name)\ncr.summary()\ncr.plot_residuals()\ncr.plot_scatter()'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:39.672473Z","iopub.execute_input":"2023-08-20T20:11:39.672883Z","iopub.status.idle":"2023-08-20T20:11:40.835793Z","shell.execute_reply.started":"2023-08-20T20:11:39.672852Z","shell.execute_reply":"2023-08-20T20:11:40.834765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ncr._model.predict(scaled_clean_test[X.columns])\n\n#cr.summary()'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:40.837299Z","iopub.execute_input":"2023-08-20T20:11:40.837592Z","iopub.status.idle":"2023-08-20T20:11:40.849654Z","shell.execute_reply.started":"2023-08-20T20:11:40.837566Z","shell.execute_reply":"2023-08-20T20:11:40.848609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''scaled_clean_test[target] = 0\ncr.predict(scaled_clean_test, X.columns, y.name)\ncr.summary()\n\ny_pred = cr.get_data()['']\ny_pred = y_pred.rename(target)\ndf = test.join(y_pred)\n#df[['Id', 'y_pred']]\ndf[['Id', target]]'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:10.136850Z","iopub.status.idle":"2023-08-20T20:11:10.137208Z","shell.execute_reply.started":"2023-08-20T20:11:10.137013Z","shell.execute_reply":"2023-08-20T20:11:10.137050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''df[['Id', 'y_pred']].to_csv('submission.csv', index=False)'''","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:11:10.139463Z","iopub.status.idle":"2023-08-20T20:11:10.139837Z","shell.execute_reply.started":"2023-08-20T20:11:10.139670Z","shell.execute_reply":"2023-08-20T20:11:10.139687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX = scaled_clean_train.drop(target, axis=1)\ny = scaled_clean_train[target]\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n\ndtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\ndtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)\n\n# Define hyperparameters\nparams = {\"objective\": \"reg:squarederror\", \"tree_method\": \"hist\"}\nevals = [(dtrain_reg, \"train\"), (dtest_reg, \"validation\")]\n\nn = 10000\n\nmodel = xgb.train(\n   params=params,\n   dtrain=dtrain_reg,\n   num_boost_round=n,\n   evals=evals,\n   verbose_eval=50,\n   # Activate early stopping\n   early_stopping_rounds=100\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:20:12.279430Z","iopub.execute_input":"2023-08-20T20:20:12.279799Z","iopub.status.idle":"2023-08-20T20:20:13.094608Z","shell.execute_reply.started":"2023-08-20T20:20:12.279771Z","shell.execute_reply":"2023-08-20T20:20:13.093747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_results = xgb.cv(dtrain=dtrain_reg, params=params, \n                  nfold=10, num_boost_round=10000, \n                  metrics=\"error\", as_pandas=True, seed=123)\n\ncv_results","metadata":{"execution":{"iopub.status.busy":"2023-08-20T15:24:34.763328Z","iopub.execute_input":"2023-08-20T15:24:34.763732Z","iopub.status.idle":"2023-08-20T15:35:17.172427Z","shell.execute_reply.started":"2023-08-20T15:24:34.763700Z","shell.execute_reply":"2023-08-20T15:35:17.170144Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = scaled_clean_train.drop(target, axis=1)\ny = scaled_clean_train[target]\n\n# Create the training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)\n\n# Instantiate the XGBRegressor: xg_reg\nxg_reg = xgb.XGBRegressor( objective='reg:squarederror', n_estimators=100, seed=123, subsample=0.5)\n\n# Fit the regressor to the training set\nxg_reg.fit(X, y)\n\n\n# Predict the labels of the test set: preds\npreds = xg_reg.predict(scaled_clean_test[X_train.columns])\n\n# Compute the rmse: rmse\n#log_rmse = np.sqrt(mean_squared_error(np.log(y_test), np.log(preds)))\n#print(f\"RMSE: {log_rmse}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:20:19.477428Z","iopub.execute_input":"2023-08-20T20:20:19.477800Z","iopub.status.idle":"2023-08-20T20:20:20.178921Z","shell.execute_reply.started":"2023-08-20T20:20:19.477769Z","shell.execute_reply":"2023-08-20T20:20:20.178172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest['SalePrice'] = xg_reg.predict(scaled_clean_test[X_train.columns])\n\ntest[['Id','SalePrice']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:24:50.127344Z","iopub.execute_input":"2023-08-20T20:24:50.127754Z","iopub.status.idle":"2023-08-20T20:24:50.154058Z","shell.execute_reply.started":"2023-08-20T20:24:50.127720Z","shell.execute_reply":"2023-08-20T20:24:50.152964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nDM_train = xgb.DMatrix(X_train, y_train, enable_categorical=True)\nDM_test =  xgb.DMatrix(X_test, y_test, enable_categorical=True)\n\nparams = {\"booster\":\"gblinear\", \"objective\":\"reg:squarederror\"}\n\nalphas = range(20, 1020, 20)\nvals = []\n\nfor alpha in tqdm(alphas):\n    params[\"alpha\"] = alpha\n    xg_reg = xgb.train(dtrain = DM_train, params=params, num_boost_round=1000)\n    preds = xg_reg.predict(DM_test)\n\n    log_rmse = np.sqrt(mean_squared_error(np.log(y_test), np.log(preds)))\n    #print(f\"alpha: {alpha} \\t| RMSE: {log_rmse : .4f}\")\n    vals.append([alpha, log_rmse])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:12:11.948913Z","iopub.execute_input":"2023-08-20T20:12:11.949304Z","iopub.status.idle":"2023-08-20T20:13:53.524401Z","shell.execute_reply.started":"2023-08-20T20:12:11.949274Z","shell.execute_reply":"2023-08-20T20:13:53.523222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmse_df = pd.DataFrame(vals, columns=['alpha', 'log_rmse'])\nrmse_df = rmse_df.set_index('alpha')\nrmse_df['log_rmse'].nlargest(10) #[['alpha', 'log_rmse']].plot(secondary_y=['alpha'])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T20:15:08.346941Z","iopub.execute_input":"2023-08-20T20:15:08.347372Z","iopub.status.idle":"2023-08-20T20:15:08.358910Z","shell.execute_reply.started":"2023-08-20T20:15:08.347335Z","shell.execute_reply":"2023-08-20T20:15:08.357829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform cross-validation: cv_results\ncv_results = xgb.cv(dtrain=DM_train, params=params, nfold=10, num_boost_round=10, metrics='rmse', as_pandas=True, seed=123)\n\n# Print cv_results\ncv_results","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:04:07.392886Z","iopub.execute_input":"2023-08-20T17:04:07.393583Z","iopub.status.idle":"2023-08-20T17:04:08.133277Z","shell.execute_reply.started":"2023-08-20T17:04:07.393547Z","shell.execute_reply":"2023-08-20T17:04:08.131523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dmatrix = xgb.DMatrix(data=X, label=y)\n\nreg_params = [0.01, 0.1, 1, 10, 100, 1000, 10000]\n\nparams = {\"objective\":\"reg:squarederror\",\"max_depth\":4}\nrmses_l2 = []\n\nfor reg in tqdm(reg_params):\n    params[\"lambda\"] = reg\n    cv_results_rmse = xgb.cv(dtrain=dmatrix, params=params, nfold=5, num_boost_round=100, metrics=\"rmse\", as_pandas=True, seed=123)\n    rmses_l2.append(cv_results_rmse[\"test-rmse-mean\"].tail(1).values[0])\n\nprint(\"Best rmse as a function of l2:\")\nprint(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=[\"l2\", \"rmse\"]))","metadata":{"execution":{"iopub.status.busy":"2023-08-20T17:08:07.600702Z","iopub.execute_input":"2023-08-20T17:08:07.601381Z","iopub.status.idle":"2023-08-20T17:08:47.777781Z","shell.execute_reply.started":"2023-08-20T17:08:07.601346Z","shell.execute_reply":"2023-08-20T17:08:47.776734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}